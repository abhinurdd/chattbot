import streamlit as st
import json
import re
import asyncio
import time
from datetime import datetime
from typing import List, Dict, Any, Tuple, Optional

from api_clients import (
    message_model,
    search_google,
    scrape_complete_instagram_profile,
    parse_normalization_response,
    parse_profile_selection_response,
    spell_correct_influencer_name,
    enhanced_influencer_normalization,
    run_async_in_sync,
    cleanup_async_resources
)
from workflow_logic import (
    build_search_query_and_filter_candidates,
    format_profile_data,
    analyze_instagram_posts,
    aggregate_post_metrics,
    calculate_scores_manually
)
from database import (
    init_db,
    check_profile_exists,
    insert_complete_profile,
    get_profile_from_cache,
    get_database_stats
)
from conversation_manager import conversation_manager
from knowledge_manager import knowledge_manager
from fast_semantic_matcher import fast_semantic_matcher
from unified_data_manager import unified_data_manager
from config import MODEL_NORMALIZER, MODEL_SELECTOR, MODEL_SCORING

import os

CHAT_JSON_PATH = "chat_conversations.json"

def save_conversations_to_json(convo_data, filename=CHAT_JSON_PATH):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(convo_data, f, indent=2, ensure_ascii=False)

def load_conversations_from_json(filename=CHAT_JSON_PATH):
    if os.path.exists(filename):
        with open(filename, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        return {}

def initialize_memory():
    if "all_conversations" not in st.session_state:
        st.session_state.all_conversations = load_conversations_from_json()
    if "active_conversation_id" not in st.session_state:
        st.session_state.active_conversation_id = str(datetime.now().timestamp())
    if st.session_state.active_conversation_id not in st.session_state.all_conversations:
        st.session_state.all_conversations[st.session_state.active_conversation_id] = []
    st.session_state.conversation_memory = st.session_state.all_conversations[st.session_state.active_conversation_id]

def add_message_to_memory(role, content):
    convo_id = st.session_state.active_conversation_id
    st.session_state.all_conversations[convo_id].append({"role": role, "content": content})
    st.session_state.conversation_memory = st.session_state.all_conversations[convo_id]
    save_conversations_to_json(st.session_state.all_conversations)

def reset_conversation_memory():
    new_id = str(datetime.now().timestamp())
    st.session_state.active_conversation_id = new_id
    st.session_state.all_conversations[new_id] = []
    st.session_state.conversation_memory = []
    save_conversations_to_json(st.session_state.all_conversations)

st.set_page_config(
    page_title="Nurdd's AI Marketing Strategist",
    page_icon="ğŸ¯",
    layout="wide"
)

def extract_influencer_names(query: str) -> List[str]:
    parts = re.split(r'\band\b|,|&', query, flags=re.IGNORECASE)
    names = []
    for part in parts:
        name = part.strip(' .:,').replace('about', '').replace('About', '').strip()
        if len(name) > 1 and re.search(r'[a-zA-Z]', name):
            names.append(name)
    names = list(set([n.strip() for n in names if n.strip()]))
    return names

def safe_ai_message_model(prompt, model):
    try:
        return message_model(prompt, model)
    except Exception as e:
        print("AI call failed, trying fallback:", e)
        try:
            import nest_asyncio
            nest_asyncio.apply()
            loop = asyncio.get_event_loop()
            result = loop.run_until_complete(message_model(prompt, model))
            return result
        except Exception as e2:
            print("Failed to run in async fallback as well:", e2)
            return ""

class AIProductMatcher:
    def __init__(self):
        pass

    def analyze_query_intent(self, query: str) -> Dict[str, Any]:
        intent_analysis_prompt = f"""
        Analyze this user query and determine their intent:
        Query: "{query}"
        Determine:
        1. Intent type: "product_promotion" (wants influencer recommendations for a product/brand) OR "influencer_info" (asking about specific influencer) OR "general_question"
        2. If product_promotion: Extract what they want to promote (be specific and descriptive)
        3. If product_promotion: Extract brand name if mentioned
        4. If influencer_info: Extract influencer name(s), support multiple names separated by comma, 'and', '&'
        Return JSON:
        {{
          "intent": "product_promotion/influencer_info/general_question",
          "product_description": "detailed description of what to promote or null",
          "brand": "extracted brand or null",
          "influencer_name": "list of names, comma separated if more than one",
          "confidence": 0.0-1.0,
          "likely_misspelling": true/false
        }}
        """
        try:
            response = safe_ai_message_model(intent_analysis_prompt, MODEL_NORMALIZER)
            if response:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    result = json.loads(json_match.group())
                    return result
        except Exception as e:
            print(f"Intent analysis error: {e}")
        return {"intent": "general_question", "confidence": 0.0, "likely_misspelling": False}

    def find_semantic_matches(self, product_description: str, brand: str = None) -> List[Dict]:
        enhanced_description = product_description
        if brand:
            enhanced_description = f"{brand} {product_description}"
        matches = fast_semantic_matcher.find_semantic_matches(
            enhanced_description,
            top_k=10
        )
        return matches

    def generate_promotion_strategy(self, product_description: str, brand: str, matched_influencers: List[Dict]) -> str:
        if not matched_influencers:
            return "âŒ **No suitable influencers found in precomputed embeddings**\n\nThis might be because:\n- The embeddings need to be regenerated with more diverse influencers\n- Try a different product description\n- Ask me to research specific influencers first"
        influencer_data = []
        for inf in matched_influencers[:5]:
            explanation = fast_semantic_matcher.explain_match(inf, product_description)
            inf_summary = {
                "name": inf.get('name', 'Unknown'),
                "username": inf.get('username', ''),
                "followers": inf.get('followers', 0),
                "engagement_rate": inf.get('engagement_rate', 0),
                "category": inf.get('category', 'Unknown'),
                "semantic_match_score": inf.get('semantic_match_score', 0),
                "match_confidence": inf.get('match_confidence', 0),
                "match_explanation": explanation,
                "verified": inf.get('verified', False),
                "top_hashtags": inf.get('top_hashtags', [])[:10]
            }
            influencer_data.append(inf_summary)
        strategy_prompt = f"""
        Create a comprehensive influencer marketing strategy for this product promotion:
        **PRODUCT TO PROMOTE:**
        {product_description}
        {f"Brand: {brand}" if brand else ""}
        **RECOMMENDED INFLUENCERS (Semantic Matches):**
        {json.dumps(influencer_data, indent=2)}
        Create a detailed marketing strategy with these sections:
        ## ğŸ¯ Campaign Overview
        ## ğŸ“Š Top Influencer Recommendations
        ## ğŸ’¡ Campaign Strategy
        ## ğŸ“ˆ Expected Results
        ## ğŸ’° Budget Estimates
        ## ğŸš€ Next Steps
        Make it professional, specific, and data-driven using the actual metrics provided.
        """
        try:
            response = safe_ai_message_model(strategy_prompt, MODEL_SCORING)
            return response if response else "Unable to generate strategy at this time."
        except Exception as e:
            print(f"Strategy generation error: {e}")
            return "Unable to generate strategy at this time."

class IntelligentChatbot:
    def __init__(self):
        self.product_matcher = AIProductMatcher()
        self.initialize_session_state()

    def initialize_session_state(self):
        initialize_memory()
        if "conversation_context" not in st.session_state:
            st.session_state.conversation_context = {}
        if "user_preferences" not in st.session_state:
            st.session_state.user_preferences = {}
        if "processed_queries" not in st.session_state:
            st.session_state.processed_queries = {}
        if "auto_scraped_influencers" not in st.session_state:
            st.session_state.auto_scraped_influencers = []
        if "data_loaded" not in st.session_state:
            st.session_state.data_loaded = False
        if "spelling_corrections" not in st.session_state:
            st.session_state.spelling_corrections = {}
        if "scraping_history" not in st.session_state:
            st.session_state.scraping_history = []
        if "async_mode" not in st.session_state:
            st.session_state.async_mode = True
        if "performance_stats" not in st.session_state:
            st.session_state.performance_stats = {
                "queries_processed": 0,
                "async_successes": 0,
                "sync_fallbacks": 0,
                "average_response_time": 0
            }

    def get_welcome_message(self) -> str:
        try:
            stats = unified_data_manager.get_database_stats()
            return f"""Hello! I'm **Nurdd's AI Marketing Strategist** ğŸ¯

I have access to **{stats['total_unique']} influencer profiles** with **robust async features**!

**ğŸš€ Performance Features:**
- **Async Optimized**: 25-50% faster processing with SSL fixes âš¡
- **Robust Fallbacks**: Sync backup when async fails ğŸ”„
- **Smart Spell Check**: "dhruv rathi" â†’ "Dhruv Rathee" âœ…
- **Auto-Scraping**: Find anyone, I'll scrape and add them! ğŸ•·ï¸
- **Error Recovery**: Graceful degradation for maximum reliability ğŸ›¡ï¸

**ğŸ’¾ Database Status:**
- Main Database: {stats['main_database']} detailed profiles
- Embeddings Database: {stats['embeddings_database']} semantic vectors  
- Async Processing: {"âœ… Enabled" if st.session_state.get('async_mode', True) else "âŒ Sync Mode"}

*All conversation context is remembered in this chat. Clear memory for a fresh start anytime.*

**ğŸ’¡ Ask me anything naturally (I handle all the complexity!):**
- *'Tell me about carry minati'* (async search + spell correction)
- *'I want to promote my gaming laptop'* (instant semantic matching)
- *'Find influencers for skincare brand'* (parallel processing)

**ğŸ¯ Now with robust error handling - I'll always try to help you!**
*What would you like to explore today?*"""
        except Exception:
            return "Hello! I'm **Nurdd's AI Marketing Strategist** ğŸ¯\nNow with **robust async optimizations** and intelligent fallbacks! âš¡"

    def ensure_all_data_loaded(self):
        if not st.session_state.data_loaded:
            with st.spinner("âš¡ Loading unified databases with robust async features..."):
                start_time = time.time()
                try:
                    unified_data_manager.ensure_all_data_loaded()
                    load_time = time.time() - start_time
                    stats = unified_data_manager.get_database_stats()
                    if stats.get('both_loaded'):
                        st.session_state.data_loaded = True
                        st.success(f"âœ… Loaded {stats['main_database']} main + {stats['embeddings_database']} embeddings in {load_time:.1f}s + robust async!")
                    else:
                        st.error("âŒ Failed to load databases. Please check your data files.")
                except Exception as e:
                    st.error(f"âŒ Database loading error: {e}")
                    st.info("ğŸ”„ System will continue with available data")

    def find_influencer_comprehensive(self, influencer_name: str) -> Tuple[bool, Dict, str]:
        try:
            if st.session_state.async_mode:
                result = unified_data_manager.find_influencer_anywhere(influencer_name, auto_scrape=True)
                st.session_state.performance_stats["async_successes"] += 1
                return result
            else:
                result = unified_data_manager._find_influencer_anywhere_sync(influencer_name, auto_scrape=True)
                st.session_state.performance_stats["sync_fallbacks"] += 1
                return result
        except Exception as e:
            print(f"Comprehensive search error: {e}")
            st.session_state.performance_stats["sync_fallbacks"] += 1
            try:
                return unified_data_manager._find_influencer_anywhere_sync(influencer_name, auto_scrape=True)
            except Exception as e2:
                print(f"Sync fallback also failed: {e2}")
                return False, None, "search_failed"

    def process_user_message(self, user_message: str) -> str:
        add_message_to_memory("user", user_message)
        start_time = time.time()
        st.session_state.performance_stats["queries_processed"] += 1
        self.ensure_all_data_loaded()
        if not st.session_state.data_loaded:
            reply = "âŒ **Databases not loaded**\n\nPlease ensure you have both `instagram_analysis.json` and `influencer_embeddings.json` files."
            add_message_to_memory("assistant", reply)
            return reply
        try:
            with st.spinner("ğŸ¤– Analyzing your request..."):
                intent_data = self.product_matcher.analyze_query_intent(user_message)
            intent = intent_data.get('intent', 'general_question')
            confidence = intent_data.get('confidence', 0.0)
            likely_misspelling = intent_data.get('likely_misspelling', False)
            intent_display = intent.replace('_', ' ').title()
            mode_indicator = "âš¡ Async" if st.session_state.async_mode else "ğŸ”„ Sync"
            if intent == "product_promotion":
                product_description = intent_data.get('product_description', '')
                brand = intent_data.get('brand')
                if not product_description:
                    reply = "I need more details about what you want to promote. Could you describe your product or service?"
                    add_message_to_memory("assistant", reply)
                    return reply
                with st.spinner(f"âš¡ Finding instant matches for: {product_description}"):
                    try:
                        semantic_matches = self.product_matcher.find_semantic_matches(product_description, brand)
                    except Exception as e:
                        st.warning(f"Semantic matching error: {e}")
                        semantic_matches = []
                if semantic_matches:
                    st.success(f"âš¡ Found {len(semantic_matches)} semantic matches instantly!")
                    with st.spinner("ğŸ¯ Creating your marketing strategy..."):
                        try:
                            strategy = self.product_matcher.generate_promotion_strategy(
                                product_description, brand, semantic_matches
                            )
                        except Exception as e:
                            st.error(f"Strategy generation error: {e}")
                            strategy = f"Found {len(semantic_matches)} matching influencers, but couldn't generate full strategy. Please try again."
                    add_message_to_memory("assistant", strategy)
                    return strategy
                else:
                    stats = unified_data_manager.get_database_stats()
                    reply = f"""âŒ **No semantic matches found for: {product_description}**

This might be because:
- The precomputed embeddings don't include influencers in this niche
- Try a different product description  
- Consider adding more influencers to your database

**Current database status:**
- Main Database: {stats['main_database']} profiles
- Embeddings Database: {stats['embeddings_database']} profiles
- Try asking about specific influencers or broader product categories"""
                    add_message_to_memory("assistant", reply)
                    return reply
            elif intent == "influencer_info":
                influencer_name_or_names = intent_data.get('influencer_name')
                if influencer_name_or_names and (',' in str(influencer_name_or_names) or ' and ' in str(influencer_name_or_names) or '&' in str(influencer_name_or_names)):
                    influencer_names = extract_influencer_names(str(influencer_name_or_names))
                else:
                    influencer_names = extract_influencer_names(user_message)
                if isinstance(influencer_names, str):
                    influencer_names = [influencer_names]
                if influencer_names and len(influencer_names) > 1:
                    influencer_results = []
                    for nm in influencer_names:
                        found, data, source = self.find_influencer_comprehensive(nm)
                        if found and data:
                            influencer_results.append(data)
                    if influencer_results:
                        strategist_prompt = (
                            "You are Nurddâ€™s AI Marketing Strategist. Your job is to help brands find and evaluate the best influencers for their campaigns.\n\n"
                            "Analyze the user's query and influencers below; Provide detailed recommendations from search results. Always:\n\n"
                            "1. Understand the Campaign: Identify brand industry, target audience, and goals (pick from: Lifestyle, Comedy, Finance, Business, Entrepreneurship, Health, Wellness, Cooking, DIY, Crafts, Sports, Travel Vlogs, Reviews, Unboxing, ASMR, Podcasts, Motivation, Personal Development, Productivity, Science, Nature, Animals, Cars, Luxury, Minimalism, Meme Culture, News, Politics, Spirituality, Astrology)\n"
                            "2. Recommend Best Matches: Highlight 4-5 top influencers with clear reasoning\n"
                            "3. Provide Strategic Insights: Explain why each influencer is suitable matching their industry.\n"
                            "4. Suggest Campaign Ideas: Offer specific collaboration concepts\n"
                            "5. Include Practical Details: Mention engagement rates, follower counts, and content style\n"
                            "6. Ask Follow-up Questions: Help refine the search further\n\n"
                            "INFLUENCERS:\n"
                            f"{json.dumps(influencer_results, indent=2)}\n\n"
                            f"USER QUERY: {user_message}\n\n"
                            "Be comprehensive, insightful, and focus on ROI and campaign effectiveness."
                        )
                        smart_response = safe_ai_message_model(strategist_prompt, MODEL_SCORING)
                        add_message_to_memory("assistant", smart_response)
                        return smart_response
                    else:
                        add_message_to_memory("assistant", "No suitable influencer profiles found for that query.")
                        return "No suitable influencer profiles found for that query."
                influencer_name = influencer_name_or_names if influencer_name_or_names else (influencer_names[0] if influencer_names else None)
                if influencer_name:
                    if likely_misspelling:
                        search_msg = f"ğŸ”¤ Checking spelling for '{influencer_name}', searching databases, and auto-scraping if needed..."
                    else:
                        search_msg = f"ğŸ” Searching for '{influencer_name}' in databases and auto-scraping if needed..."
                    with st.spinner(search_msg):
                        try:
                            found, data, source = self.find_influencer_comprehensive(influencer_name)
                        except Exception as e:
                            st.error(f"Search error: {e}")
                            found, data, source = False, None, "search_error"
                    if found and data:
                        actual_name = data.get('basic_info', {}).get('name', influencer_name)
                        username = data.get('basic_info', {}).get('username', '')
                        if source.startswith("auto_scraped"):
                            st.success(f"ğŸ•·ï¸ **Auto-scraped and added:** {actual_name} (@{username}) to database!")
                            st.info("ğŸ†• **Fresh data** scraped from Instagram and saved to database")
                            st.session_state.scraping_history.append({
                                'name': actual_name,
                                'username': username,
                                'original_query': influencer_name,
                                'timestamp': datetime.now().isoformat()
                            })
                        elif actual_name.lower() != influencer_name.lower():
                            st.success(f"âœ… Found **{actual_name}** (@{username}) in {source.split(':')[0]} database!")
                            st.info(f"ğŸ”¤ **Spelling corrected:** '{influencer_name}' â†’ '{actual_name}'")
                            st.session_state.spelling_corrections[influencer_name.lower()] = actual_name
                        else:
                            st.success(f"âœ… Found **{actual_name}** (@{username}) in {source.split(':')[0]} database!")
                        st.session_state.processed_queries[username] = data
                        enhanced_message = f"Tell me about {actual_name}. I have their complete profile data."
                        try:
                            response = conversation_manager.generate_intelligent_response(
                                enhanced_message, st.session_state.conversation_memory
                            )
                        except Exception as e:
                            st.warning(f"Response generation error: {e}")
                            response = f"Found {actual_name} (@{username}) with {data.get('basic_info', {}).get('followers_count', 0):,} followers. However, I couldn't generate the detailed analysis. Please try asking again."
                        add_message_to_memory("assistant", response)
                        return response
                    else:
                        stats = unified_data_manager.get_database_stats()
                        error_msg = f"""âŒ **Could not find "{influencer_name}" anywhere**
**ğŸš€ Complete Search Process (Robust Mode):**
- âœ… AI spell check and correction
- âœ… Searched {stats['main_database']} main profiles
- âœ… Searched {stats['embeddings_database']} embeddings profiles
- âœ… Google search for Instagram profile
- âŒ Auto-scraping failed or no Instagram profile found
- âœ… Multiple fallback strategies attempted
**ğŸ’¡ Possible reasons:**
- This person may not be an Instagram influencer
- Their Instagram profile might be private
- Try using their exact Instagram username
- Check if the name is spelled correctly
**Recent Auto-Scraped:** """
                        if st.session_state.scraping_history:
                            recent_scraped = st.session_state.scraping_history[-3:]
                            for scraped in recent_scraped:
                                error_msg += f"\n- {scraped['name']} (@{scraped['username']})"
                        else:
                            error_msg += "None yet"
                        add_message_to_memory("assistant", error_msg)
                        return error_msg
            try:
                response = conversation_manager.generate_intelligent_response(
                    user_message, st.session_state.conversation_memory
                )
                add_message_to_memory("assistant", response)
                return response
            except Exception as e:
                reply = "I apologize, but I encountered an error processing your question. Please try rephrasing or asking something else."
                add_message_to_memory("assistant", reply)
                return reply
        except Exception as e:
            reply = f"I encountered an error while processing your request: {str(e)}. Please try again or contact support if the issue persists."
            add_message_to_memory("assistant", reply)
            return reply
        finally:
            processing_time = time.time() - start_time
            current_avg = st.session_state.performance_stats["average_response_time"]
            queries_count = st.session_state.performance_stats["queries_processed"]
            st.session_state.performance_stats["average_response_time"] = (
                (current_avg * (queries_count - 1) + processing_time) / queries_count
            )

    def render_chat_interface(self):
        st.title("ğŸ¯ Nurdd's AI Marketing Strategist")
        st.caption("ğŸš€ Robust Async â€¢ ğŸ”„ Smart Fallbacks â€¢ ğŸ”¤ AI Spell Check â€¢ ğŸ•·ï¸ Auto-Scraping â€¢ ğŸ›¡ï¸ Error Recovery")
        try:
            init_db()
            stats = unified_data_manager.get_database_stats()
            mode = "Async" if st.session_state.async_mode else "Sync"
            st.success(f"âœ… Robust access: {stats['main_database']} main + {stats['embeddings_database']} embeddings ({mode} mode)")
        except Exception as e:
            st.error(f"âŒ Database error: {e}")
            st.info("ğŸ”„ System will continue with available functionality")
        if st.button("ğŸ—‘ï¸ Start New Conversation"):
            reset_conversation_memory()
            add_message_to_memory("assistant", self.get_welcome_message())
            st.rerun()
        for message in st.session_state.conversation_memory:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        placeholder_text = "Ask about any influencer (ğŸš€ robust async + fallbacks!) or describe what you want to promote..."
        if prompt := st.chat_input(placeholder_text):
            add_message_to_memory("user", prompt)
            with st.chat_message("user"):
                st.markdown(prompt)
            with st.chat_message("assistant"):
                response = self.process_user_message(prompt)
                st.markdown(response)

    def render_sidebar(self):
        with st.sidebar:
            st.header("ğŸ”§ Controls")
            st.write(
                "The chatbot remembers context for your current session. "
                "Start a new conversation anytime to clear memory."
            )
            st.write(f"Current Conversation: {st.session_state.active_conversation_id}")
            st.write(f"Messages in session: {len(st.session_state.conversation_memory)}")
            if st.button("ğŸ—‘ï¸ Start Fresh Memory"):
                reset_conversation_memory()
                add_message_to_memory("assistant", self.get_welcome_message())
                st.success("Started a new conversation. Memory cleared.")
                st.rerun()
            st.header("âš¡ Processing Mode")
            async_mode = st.checkbox("Enable Async Mode", value=st.session_state.async_mode)
            if async_mode != st.session_state.async_mode:
                st.session_state.async_mode = async_mode
                st.success(f"Switched to {'Async' if async_mode else 'Sync'} mode")
            if async_mode:
                st.success("ğŸš€ Async mode active (faster)")
            else:
                st.info("ğŸ”„ Sync mode active (reliable)")
            st.header("ğŸš€ Robust Performance")
            stats = unified_data_manager.get_database_stats()
            perf_stats = st.session_state.performance_stats
            if st.session_state.data_loaded:
                st.success("âœ… All Systems Ready (Robust)")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Main DB", stats['main_database'])
                    st.metric("Queries Processed", perf_stats["queries_processed"])
                    st.metric("Avg Response Time", f"{perf_stats['average_response_time']:.1f}s")
                with col2:
                    st.metric("Embeddings", stats['embeddings_database']) 
                    st.metric("Async Successes", perf_stats["async_successes"])
                    st.metric("Sync Fallbacks", perf_stats["sync_fallbacks"])
                if perf_stats["queries_processed"] > 0:
                    async_rate = (perf_stats["async_successes"] / perf_stats["queries_processed"]) * 100
                    if async_rate > 80:
                        st.success(f"âš¡ Async Success Rate: {async_rate:.0f}%")
                    elif async_rate > 50:
                        st.warning(f"ğŸ”„ Async Success Rate: {async_rate:.0f}%")
                    else:
                        st.error(f"ğŸ”„ Async Success Rate: {async_rate:.0f}%")
            else:
                st.warning("â³ Systems will load on first query")
            if st.button("ğŸ”„ Reload All Data"):
                st.session_state.data_loaded = False
                unified_data_manager.main_db_loaded = False
                unified_data_manager.embeddings_loaded = False
                fast_semantic_matcher.is_loaded = False
                st.session_state.performance_stats = {
                    "queries_processed": 0,
                    "async_successes": 0,
                    "sync_fallbacks": 0,
                    "average_response_time": 0
                }
                st.success("Data will reload on next query")
            st.header("ğŸ•·ï¸ Robust Auto-Scraping")
            current_auto_scraping = unified_data_manager.auto_scraping_enabled
            new_auto_scraping = st.checkbox("Enable Auto-Scraping", value=current_auto_scraping)
            if new_auto_scraping != current_auto_scraping:
                unified_data_manager.toggle_auto_scraping(new_auto_scraping)
            if new_auto_scraping:
                st.success("âš¡ Robust scraping enabled (async + sync fallbacks)")
            else:
                st.warning("âš ï¸ Auto-scraping disabled")
            if st.session_state.scraping_history:
                st.metric("Auto-Scraped Today", len(st.session_state.scraping_history))
                st.subheader("Recently Scraped:")
                recent = st.session_state.scraping_history[-5:]
                for scraped in recent:
                    st.text(f"â€¢ {scraped['name']} (@{scraped['username']})")
                if st.button("ğŸ—‘ï¸ Clear Scraping History"):
                    st.session_state.scraping_history = []
                    st.success("Scraping history cleared!")
            else:
                st.text("No robust scraping done yet")
            st.header("ğŸ”¤ Smart Spell Check")
            if st.session_state.spelling_corrections:
                st.metric("Corrections Made", len(st.session_state.spelling_corrections))
                st.subheader("Recent Corrections:")
                recent = list(st.session_state.spelling_corrections.items())[-5:]
                for orig, corrected in recent:
                    st.text(f"'{orig}' â†’ '{corrected}'")
                if st.button("ğŸ—‘ï¸ Clear Correction History"):
                    st.session_state.spelling_corrections = {}
                    st.success("Correction history cleared!")
            else:
                st.text("No corrections made yet")
            st.header("ğŸ’¡ Try These Examples")
            examples = [
                "What do you know about dhruv rathi?",     
                "Tell me about carry minati",             
                "What about harsh beniwall?",             
                "Tell me about triggered insaan",         
                "I want to promote my gaming laptop",     
                "Find influencers for my skincare brand", 
                "Who should advertise my fitness app?",   
                "What about bhuvan bam?",                 
                "Tell me about any influencer name",      
            ]
            for example in examples:
                if st.button(example, key=f"ex_{hash(example)}"):
                    add_message_to_memory("user", example)
                    st.rerun()
            st.header("ğŸ›¡ï¸ Robust Features")
            st.info("""
            **âš¡ Performance Optimizations:**
            - Async processing: 25-50% faster
            - Sync fallbacks: 100% reliability
            - Connection pooling: Efficient HTTP
            - Error recovery: Graceful degradation

            **ğŸ”¤ Smart Features:**
            - AI spell correction: Works with errors
            - Fuzzy name matching: Finds variations
            - Cross-database search: Comprehensive
            - SSL fixes: Handles certificate issues

            **ğŸ•·ï¸ Auto-Scraping:**
            - Robust Google search
            - Parallel profile + posts scraping
            - Multiple fallback strategies
            - Error handling at every step

            **ğŸ›¡ï¸ Reliability:**
            - Multiple error recovery paths
            - Graceful degradation
            - Performance monitoring
            - Success rate tracking
            """)

    def run(self):
        self.render_chat_interface()
        self.render_sidebar()

if __name__ == "__main__":
    chatbot = IntelligentChatbot()
    chatbot.run()
